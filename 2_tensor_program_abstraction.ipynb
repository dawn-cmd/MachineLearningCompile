{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlc-ai/notebooks/blob/main/2_tensor_program_abstraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpn1ti5Urdsv"
      },
      "source": [
        "# Tensor Program Abstraction in Action\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXysoqn-vZuF"
      },
      "source": [
        "## Install packages \n",
        "\n",
        "For the purpose of this course, we will use some on-going development in tvm, which is an open source machine learning compilation framework. We provide the following command to install a packaged version for mlc course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe3vClsD9jlq",
        "outputId": "6d336487-f44b-45cc-ca2c-bae60a295cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://mlc.ai/wheels\n",
            "Requirement already satisfied: mlc-ai-nightly in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (0.15.dev559)\n",
            "Collecting mlc-llm-nightly\n",
            "  Downloading https://github.com/mlc-ai/package/releases/download/v0.9.dev0/mlc_llm_nightly-0.1.dev1519-cp311-cp311-manylinux_2_28_x86_64.whl (51.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (3.0.0)\n",
            "Requirement already satisfied: decorator in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (5.1.1)\n",
            "Requirement already satisfied: ml-dtypes in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (0.4.0)\n",
            "Requirement already satisfied: numpy in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (2.1.0)\n",
            "Requirement already satisfied: packaging in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (24.1)\n",
            "Requirement already satisfied: psutil in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (6.0.0)\n",
            "Requirement already satisfied: scipy in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (1.14.1)\n",
            "Requirement already satisfied: tornado in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (6.4.1)\n",
            "Requirement already satisfied: typing-extensions in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-ai-nightly) (4.12.2)\n",
            "Collecting fastapi (from mlc-llm-nightly)\n",
            "  Downloading fastapi-0.112.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn (from mlc-llm-nightly)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting shortuuid (from mlc-llm-nightly)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torch (from mlc-llm-nightly)\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting safetensors (from mlc-llm-nightly)\n",
            "  Downloading safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: requests in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-llm-nightly) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-llm-nightly) (4.66.5)\n",
            "Collecting tiktoken (from mlc-llm-nightly)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: prompt-toolkit in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from mlc-llm-nightly) (3.0.47)\n",
            "Collecting openai (from mlc-llm-nightly)\n",
            "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->mlc-llm-nightly)\n",
            "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi->mlc-llm-nightly)\n",
            "  Downloading pydantic-2.9.0b2-py3-none-any.whl.metadata (146 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai->mlc-llm-nightly)\n",
            "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai->mlc-llm-nightly)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai->mlc-llm-nightly)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai->mlc-llm-nightly)\n",
            "  Downloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting sniffio (from openai->mlc-llm-nightly)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: wcwidth in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from prompt-toolkit->mlc-llm-nightly) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from requests->mlc-llm-nightly) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from requests->mlc-llm-nightly) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from requests->mlc-llm-nightly) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /mnt/702677352676FB82/Code/.conda/lib/python3.11/site-packages (from requests->mlc-llm-nightly) (2024.8.30)\n",
            "Collecting regex>=2022.1.18 (from tiktoken->mlc-llm-nightly)\n",
            "  Downloading regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting filelock (from torch->mlc-llm-nightly)\n",
            "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting sympy (from torch->mlc-llm-nightly)\n",
            "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch->mlc-llm-nightly)\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch->mlc-llm-nightly)\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch->mlc-llm-nightly)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch->mlc-llm-nightly)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mlc-llm-nightly)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting click>=7.0 (from uvicorn->mlc-llm-nightly)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting h11>=0.8 (from uvicorn->mlc-llm-nightly)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->mlc-llm-nightly)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->mlc-llm-nightly)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.23.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->mlc-llm-nightly)\n",
            "  Downloading pydantic_core-2.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tzdata (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->mlc-llm-nightly)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->mlc-llm-nightly)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch->mlc-llm-nightly)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading fastapi-0.112.2-py3-none-any.whl (93 kB)\n",
            "Downloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
            "Downloading safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
            "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Downloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "Downloading pydantic-2.9.0b2-py3-none-any.whl (434 kB)\n",
            "Downloading pydantic_core-2.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (786 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.6/786.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
            "Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Installing collected packages: mpmath, tzdata, sympy, sniffio, shortuuid, safetensors, regex, pydantic-core, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, jiter, h11, fsspec, filelock, distro, click, annotated-types, uvicorn, triton, tiktoken, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, httpcore, anyio, starlette, nvidia-cusolver-cu12, httpx, torch, openai, fastapi, mlc-llm-nightly\n",
            "Successfully installed MarkupSafe-2.1.5 annotated-types-0.7.0 anyio-4.4.0 click-8.1.7 distro-1.9.0 fastapi-0.112.2 filelock-3.15.4 fsspec-2024.6.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jinja2-3.1.4 jiter-0.5.0 mlc-llm-nightly-0.1.dev1519 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 openai-1.43.0 pydantic-2.9.0b2 pydantic-core-2.23.1 regex-2024.7.24 safetensors-0.4.4 shortuuid-1.0.13 sniffio-1.3.1 starlette-0.38.2 sympy-1.13.2 tiktoken-0.7.0 torch-2.4.0 triton-3.0.0 tzdata-2024.1 uvicorn-0.30.6\n"
          ]
        }
      ],
      "source": [
        "# %pip install --pre mlc-ai-nightly -f https://mlc.ai/wheels\n",
        "# %pip install tlcpack-nightly -f https://tlcpack.ai/wheels\n",
        "!python3 -m pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly mlc-llm-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIuE2jc1DaU"
      },
      "source": [
        "## Constructing Tensor Program\n",
        "\n",
        "Let us begin by constructing a tensor program that performs addition among two vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vvfOgcu-YdaB"
      },
      "outputs": [],
      "source": [
        "import tvm\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import tir as T\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qCViJNUNYfTW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_35147/47748708.py:4: DeprecationWarning: T.Buffer[...] is deprecated, use T.Buffer(...) instead\n",
            "  def main(A: T.Buffer[128, \"float32\"],\n",
            "/tmp/ipykernel_35147/47748708.py:5: DeprecationWarning: T.Buffer[...] is deprecated, use T.Buffer(...) instead\n",
            "  B: T.Buffer[128, \"float32\"],\n",
            "/tmp/ipykernel_35147/47748708.py:6: DeprecationWarning: T.Buffer[...] is deprecated, use T.Buffer(...) instead\n",
            "  C: T.Buffer[128, \"float32\"]):\n",
            "<ast>:3: DeprecationWarning: T.Buffer[...] is deprecated, use T.Buffer(...) instead\n"
          ]
        }
      ],
      "source": [
        "@tvm.script.ir_module\n",
        "class MyModule:\n",
        "    @T.prim_func\n",
        "    def main(A: T.Buffer[128, \"float32\"], \n",
        "             B: T.Buffer[128, \"float32\"], \n",
        "             C: T.Buffer[128, \"float32\"]):\n",
        "        # extra annotations for the function\n",
        "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
        "        for i in range(128):\n",
        "            with T.block(\"C\"):\n",
        "                # declare a data parallel iterator on spatial domain\n",
        "                vi = T.axis.spatial(128, i)\n",
        "                C[vi] = A[vi] + B[vi]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PJd0Pw8zVQD"
      },
      "source": [
        "TVMScript is a way for us to express tensor program in python ast. Note that this code do not actually correspond to a python program, but a tensor program  that can be used in MLC process. The language is designed to align with python syntax with additional structures to facilitate analysis and transformation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKsLAcDB8Npx",
        "outputId": "8534ef46-c656-4f36-961c-f6e59e04ad6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tvm.ir.module.IRModule"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(MyModule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpdPoa5q8Sj7"
      },
      "source": [
        "MyModule is an instance of an **IRModule** data structure, which is used to hold a collection of tensor functions. \n",
        "\n",
        "We can use the `show()` function to get a highlighted string based representation of the IRModule. This function is quite useful for inspecting the module during each step of transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXy-4v3Czax9",
        "outputId": "c933d1e0-42d5-4df2-ad9a-6eb997deb10c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i <span style=\"color: #008000; font-weight: bold\">in</span> range(<span style=\"color: #008000\">128</span>):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
              "                vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i)\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[vi], B[vi])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[vi])\n",
              "                C[vi] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[vi] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[vi]\n",
              "</pre></div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MyModule.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "sch = tvm.tir.Schedule(MyModule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_c = sch.get_block(\"C\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "i, = sch.get_loops(block_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "i0, i1, i2 = sch.split(i, factors=[None, 4, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((128,), \"float32\"), B: T.Buffer((128,), \"float32\"), C: T.Buffer((128,), \"float32\")):\n",
            "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
            "        # with T.block(\"root\"):\n",
            "        for i_0, i_1, i_2 in T.grid(8, 4, 4):\n",
            "            with T.block(\"C\"):\n",
            "                vi = T.axis.spatial(128, i_0 * 16 + i_1 * 4 + i_2)\n",
            "                T.reads(A[vi], B[vi])\n",
            "                T.writes(C[vi])\n",
            "                C[vi] = A[vi] + B[vi]\n"
          ]
        }
      ],
      "source": [
        "print(sch.mod.script())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((128,), \"float32\"), B: T.Buffer((128,), \"float32\"), C: T.Buffer((128,), \"float32\")):\n",
            "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
            "        # with T.block(\"root\"):\n",
            "        for i_0 in T.parallel(8):\n",
            "            for i_2, i_1 in T.grid(4, 4):\n",
            "                with T.block(\"C\"):\n",
            "                    vi = T.axis.spatial(128, i_0 * 16 + i_1 * 4 + i_2)\n",
            "                    T.reads(A[vi], B[vi])\n",
            "                    T.writes(C[vi])\n",
            "                    C[vi] = A[vi] + B[vi]\n"
          ]
        }
      ],
      "source": [
        "sch.reorder(i2, i1)\n",
        "sch.parallel(i0)\n",
        "print(sch.mod.script())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOMSOuW6aIJg"
      },
      "source": [
        "### Build and run\n",
        "\n",
        "Any any time point, we can turn an IRModule to runnable functions by calling a build function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oESoqN-xaTCf",
        "outputId": "58119fbd-b737-400d-bd94-776af0709501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'tvm.driver.build_module.OperatorModule'>\n"
          ]
        }
      ],
      "source": [
        "rt_mod = tvm.build(sch.mod, target=\"llvm\")  # The module for CPU backends.\n",
        "print(type(rt_mod))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2ZfGrH1z6SV"
      },
      "source": [
        "After build, mod contains a collection of runnable functions. We can retrieve each function by its name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5I3GqwnRz-Ne"
      },
      "outputs": [],
      "source": [
        "func = rt_mod[\"main\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bngdW1eVl683",
        "outputId": "d5e0437c-bf16-4107-aa41-e11a4e1865ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tvm.runtime.packed_func.PackedFunc at 0x79c93c1573e0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DKxo8uq_mNlp"
      },
      "outputs": [],
      "source": [
        "a = tvm.nd.array(np.arange(128, dtype=\"float32\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1hAFAqv_mP8W"
      },
      "outputs": [],
      "source": [
        "b = tvm.nd.array(np.ones(128, dtype=\"float32\")) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TseB1UBumivT"
      },
      "outputs": [],
      "source": [
        "c = tvm.nd.empty((128,), dtype=\"float32\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p68xZ0_P0MPw"
      },
      "source": [
        "To invoke the function, we can create three NDArrays in the tvm runtime, and then invoke the generated function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SMkcgO-L0Xr5"
      },
      "outputs": [],
      "source": [
        "func(a, b, c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AakkTpE50b6o",
        "outputId": "43971a60-2fbb-41bb-cc47-c496bfe5dda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
            "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
            "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
            "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
            "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
            "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
            "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
            "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
            " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
            " 126. 127.]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
            "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n",
            "  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.\n",
            "  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.\n",
            "  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.\n",
            "  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.\n",
            "  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.  98.\n",
            "  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.\n",
            " 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.\n",
            " 127. 128.]\n"
          ]
        }
      ],
      "source": [
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_MIDZCOcmwp"
      },
      "source": [
        "## Transform the Tensor Program\n",
        "\n",
        "Now let us start to transform the Tensor Program. A tensor prigram can be transformed using an auxiliary data structure called schedule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwyjwh51cjWI",
        "outputId": "d8a8687a-a722-4899-c181-9ca90c7d841e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'tvm.tir.schedule.schedule.Schedule'>\n"
          ]
        }
      ],
      "source": [
        "sch = tvm.tir.Schedule(MyModule)\n",
        "print(type(sch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw7Fgw8o8HPm"
      },
      "source": [
        "Let us first try to split the loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNQf8D0ic4me",
        "outputId": "1cbfd7f9-a807-4571-b2e3-66ffe052037d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i_0, i_1, i_2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
              "                vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">4</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_2)\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[vi], B[vi])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[vi])\n",
              "                C[vi] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[vi] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[vi]\n",
              "</pre></div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get block by its name\n",
        "block_c = sch.get_block(\"C\")\n",
        "# Get loops surronding the block\n",
        "(i,) = sch.get_loops(block_c)\n",
        "# Tile the loop nesting.\n",
        "i_0, i_1, i_2 = sch.split(i, factors=[None, 4, 4])\n",
        "sch.mod.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzrbvqBSdC-D"
      },
      "source": [
        "We can also reorder the loops. Now we move loop i_2 to outside of i_1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJWBq7lRdDmn",
        "outputId": "1957cf67-f51c-4af1-c5ca-16c9718181a0"
      },
      "outputs": [],
      "source": [
        "sch.reorder(i_0, i_2, i_1)\n",
        "sch.mod.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmUr6b_L07-8"
      },
      "source": [
        "Finally, we can add hints to the program generator that we want to vectorize the inner most loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u95zQFuldHs_",
        "outputId": "b2205442-ac70-405c-8f42-ddb23e46e012"
      },
      "outputs": [],
      "source": [
        "sch.mod.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7NFPx9fy5Wy"
      },
      "outputs": [],
      "source": [
        "sch.parallel(i_0)\n",
        "sch.mod.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhGlqLTG_tNv"
      },
      "source": [
        "We can build and run the transformed program\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCIYSDrI_wGq"
      },
      "outputs": [],
      "source": [
        "transformed_mod = tvm.build(sch.mod, target=\"llvm\")  # The module for CPU backends.\n",
        "transformed_mod[\"main\"](a, b, c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj_01P4mAfu2"
      },
      "source": [
        "## Constructing Tensor Program using Tensor Expression\n",
        "\n",
        "In the previous example, we directly use TVMScript to construct the tensor program. In practice, it is usually helpful to construct these functions pragmatically from existing definitions. Tensor expression is an API that helps us to build some of the expression-like array computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZAPcqbGAesY",
        "outputId": "ac4d6407-8dea-4c75-d166-e071ffee8783"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i <span style=\"color: #008000; font-weight: bold\">in</span> range(<span style=\"color: #008000\">128</span>):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
              "                v_i <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i)\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i], B[v_i])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[v_i])\n",
              "                C[v_i] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_i] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[v_i]\n",
              "</pre></div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# namespace for tensor expression utility\n",
        "from tvm import te\n",
        "\n",
        "# declare the computation using the expression API\n",
        "A = te.placeholder((128, ), name=\"A\")\n",
        "B = te.placeholder((128, ), name=\"B\")\n",
        "C = te.compute((128,), lambda i: A[i] + B[i], name=\"C\")\n",
        "\n",
        "# create a function with the specified list of arguments. \n",
        "func = te.create_prim_func([A, B, C])\n",
        "# mark that the function name is main\n",
        "func = func.with_attr(\"global_symbol\", \"main\")\n",
        "ir_mod_from_te = IRModule({\"main\": func})\n",
        "\n",
        "ir_mod_from_te.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEqpO14Lf0Lq"
      },
      "source": [
        "## Transforming a matrix multiplication program\n",
        "\n",
        "In the above example, we showed how to transform an vector add. Now let us try to apply that to a slightly more complicated program(matrix multiplication). Let us first try to build the initial code using the tensor expression API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9ExHE3BfYYv",
        "outputId": "0d82d527-8051-4bc3-c3a7-0cbb12d9bcce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> m, n, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
              "                v_m, v_n, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [m, n, k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_m, v_k], B[v_k, v_n])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[v_m, v_n])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
              "                C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">=</span> C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_m, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_n]\n",
              "</pre></div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline: 5.608619\n"
          ]
        }
      ],
      "source": [
        "from tvm import te\n",
        "\n",
        "M = 1024\n",
        "K = 1024\n",
        "N = 1024\n",
        "\n",
        "# The default tensor type in tvm\n",
        "dtype = \"float32\"\n",
        "\n",
        "target = \"llvm\"\n",
        "dev = tvm.device(target, 0)\n",
        "\n",
        "# Algorithm\n",
        "k = te.reduce_axis((0, K), \"k\")\n",
        "A = te.placeholder((M, K), name=\"A\")\n",
        "B = te.placeholder((K, N), name=\"B\")\n",
        "C = te.compute((M, N), lambda m, n: te.sum(A[m, k] * B[k, n], axis=k), name=\"C\")\n",
        "\n",
        "# Default schedule\n",
        "func = te.create_prim_func([A, B, C])\n",
        "func = func.with_attr(\"global_symbol\", \"main\")\n",
        "ir_module = IRModule({\"main\": func})\n",
        "ir_module.show()\n",
        "\n",
        "\n",
        "func = tvm.build(ir_module, target=\"llvm\")  # The module for CPU backends.\n",
        "\n",
        "a = tvm.nd.array(np.random.rand(M, K).astype(dtype), dev)\n",
        "b = tvm.nd.array(np.random.rand(K, N).astype(dtype), dev)\n",
        "c = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev)\n",
        "func(a, b, c)\n",
        "\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
        "print(\"Baseline: %f\" % evaluator(a, b, c).mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swj-gMz-1vBE"
      },
      "source": [
        "We can transform the loop access pattern to make it more cache friendly. Let us use the following schedule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W60q68KRgdNL",
        "outputId": "b49a101e-5148-4cf0-df88-0e112e741381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'tvm.tir.schedule.schedule.Schedule'>\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">1024</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> m_0, n_0, k, m_1, n_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1024</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">32</span>):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
              "                v_m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1024</span>, m_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">32</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> m_1)\n",
              "                v_n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1024</span>, n_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">32</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> n_1)\n",
              "                v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(<span style=\"color: #008000\">1024</span>, k)\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_m, v_k], B[v_k, v_n])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[v_m, v_n])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
              "                C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">=</span> C[v_m, v_n] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_m, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_n]\n",
              "</pre></div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "after transformation: 0.226694\n"
          ]
        }
      ],
      "source": [
        "sch = tvm.tir.Schedule(ir_module)\n",
        "print(type(sch))\n",
        "block_c = sch.get_block(\"C\")\n",
        "# Get loops surronding the block\n",
        "(y, x, k) = sch.get_loops(block_c)\n",
        "block_size = 32\n",
        "yo, yi = sch.split(y, [None, block_size])\n",
        "xo, xi = sch.split(x, [None, block_size])\n",
        "\n",
        "sch.reorder(yo, xo, k, yi, xi)\n",
        "sch.mod.show()\n",
        "\n",
        "func = tvm.build(sch.mod, target=\"llvm\")  # The module for CPU backends.\n",
        "\n",
        "c = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev)\n",
        "func(a, b, c)\n",
        "\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1)\n",
        "print(\"after transformation: %f\" % evaluator(a, b, c).mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1RQGOBjn4w_"
      },
      "source": [
        "Try to change the value of bn to see what performance you can get. In pratice, we will leverage an automated system to search over a set of possible transfromations to find an optimal one."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "2-tensor-program-abstraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
